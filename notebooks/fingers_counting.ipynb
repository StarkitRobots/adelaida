{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import find_contours\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "sys.path.append(\"../modules/\")\n",
    "\n",
    "import input_output\n",
    "import processor\n",
    "import image_processing\n",
    "\n",
    "det = processor.Processors ()\n",
    "det.add_processor (\"fingers_counting\")\n",
    "\n",
    "det.add_filter (processor.colorspace_to_colorspace (\"RGB\", \"HSV\"),\n",
    "                \"fingers_counting\", \"colorspace change\")\n",
    "\n",
    "low_th  = (50, 0, 145)\n",
    "high_th = (255, 255, 255)\n",
    "det.add_filter (processor.inrange (low_th, high_th), \"fingers_counting\", \"inrange rgb\")\n",
    "\n",
    "cv2.namedWindow ('trackbars')\n",
    "\n",
    "start_val = list (low_th) + list (high_th)\n",
    "\n",
    "cv2.createTrackbar (\"lr\", \"trackbars\", start_val [0], 255, \n",
    "    lambda new_coeff : det.processors [\"fingers_counting\"]\n",
    "    [\"inrange rgb\"].set_th (new_coeff, \"low\", 0))\n",
    "\n",
    "cv2.createTrackbar (\"hr\", \"trackbars\", start_val [3], 255, \n",
    "    lambda new_coeff : det.processors [\"fingers_counting\"]\n",
    "    [\"inrange rgb\"].set_th (new_coeff, \"high\", 0))\n",
    "\n",
    "cv2.createTrackbar (\"lg\", \"trackbars\", start_val [1], 255, \n",
    "    lambda new_coeff : det.processors [\"fingers_counting\"]\n",
    "    [\"inrange rgb\"].set_th (new_coeff, \"low\", 1))\n",
    "\n",
    "cv2.createTrackbar (\"hg\", \"trackbars\", start_val [4], 255, \n",
    "    lambda new_coeff : det.processors [\"fingers_counting\"]\n",
    "    [\"inrange rgb\"].set_th (new_coeff, \"high\", 1))\n",
    "\n",
    "cv2.createTrackbar (\"lb\", \"trackbars\", start_val [2], 255, \n",
    "    lambda new_coeff : det.processors [\"fingers_counting\"]\n",
    "    [\"inrange rgb\"].set_th (new_coeff, \"low\", 2))\n",
    "\n",
    "cv2.createTrackbar (\"hb\", \"trackbars\", start_val [5], 255, \n",
    "    lambda new_coeff : det.processors [\"fingers_counting\"]\n",
    "    [\"inrange rgb\"].set_th (new_coeff, \"high\", 2))\n",
    "\n",
    "det.add_filter (processor.morphology (\"open\", 5), \"fingers_counting\", \"morphological opening\")\n",
    "det.add_filter (processor.leave_max_area_cc (), \"fingers_counting\", \"leave max area cc\")\n",
    "\n",
    "det.add_filter (processor.custom_operation (lambda img: image_processing.fill_holes (img),\n",
    "                \"to_simply_connected\"), \"fingers_counting\", \"to simply connected\")\n",
    "\n",
    "det.add_filter (processor.custom_operation (lambda img: cv2.medianBlur (img, 23),\n",
    "                \"median_blur\"), \"fingers_counting\", \"median blur\")\n",
    "\n",
    "additional_stages = []\n",
    "\n",
    "def extract_and_filter_endpoints (img):\n",
    "    global additional_stages\n",
    "    \n",
    "    def detect_endpts(skeleton):\n",
    "\n",
    "        end_kernel = [[1,  1, 1],\n",
    "                      [1, 10, 1],\n",
    "                      [1,  1, 1]]\n",
    "\n",
    "        detected = convolve(skeleton, end_kernel)\n",
    "        where_detected = np.where(detected == 11)\n",
    "        end_points = [[where_detected[0][i], where_detected[1][i]] for i in\n",
    "                      range(where_detected[0].shape[0])]\n",
    "\n",
    "        return end_points\n",
    "\n",
    "    def get_contour(binary):\n",
    "        # returns image of contour of shape from <binary> as the 1st output\n",
    "        # and a list of contour points as the 2nd output\n",
    "\n",
    "        contour_points = find_contours(binary, 0.5)\n",
    "        if contour_points:\n",
    "            contour_points = contour_points[0].astype(int)\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        contour = np.zeros_like(binary)\n",
    "        \n",
    "        for point in contour_points:\n",
    "            contour[point[0]][point[1]] = 1\n",
    "        \n",
    "        return contour\n",
    "\n",
    "    def remove_endpts(contour, end_points, kern_sz=65, min_score=5):\n",
    "        assert kern_sz % 2 == 1, \"kern_sz should be odd number!\"\n",
    "        \n",
    "        if (isinstance(contour, int)):\n",
    "            return []\n",
    "\n",
    "        height, width = contour.shape\n",
    "\n",
    "        # create star-like kernel\n",
    "        kernel = np.zeros((kern_sz, kern_sz), dtype='int')\n",
    "        kernel[kern_sz // 2, :] = 1\n",
    "        kernel[:, kern_sz // 2] = 1\n",
    "        for i in range(kern_sz):\n",
    "            kernel[i, i] = 1\n",
    "            kernel[i, kern_sz - i - 1] = 1\n",
    "\n",
    "        scores = []\n",
    "        for pt in end_points:\n",
    "            score_penalty = 0\n",
    "            \n",
    "            if (pt[0] >= height - 5 or\n",
    "                pt[0] <= 5 or\n",
    "                pt[1] >= width - 5 or\n",
    "                pt[1] <= 5):\n",
    "                score_penalty = 10\n",
    "            \n",
    "            x1 = pt[1] - kern_sz // 2\n",
    "            y1 = pt[0] - kern_sz // 2\n",
    "            x2 = x1 + kern_sz\n",
    "            y2 = y1 + kern_sz\n",
    "            x1_shift, x2_shift, y1_shift, y2_shift = 0, 0, 0, 0\n",
    "            if x1 < 0:\n",
    "                x1_shift = -x1\n",
    "                x1 = 0\n",
    "            if x2 > width:\n",
    "                x2_shift = x2 - width\n",
    "                x2 = width\n",
    "            if y1 < 0:\n",
    "                y1_shift = -y1\n",
    "                y1 = 0\n",
    "            if y2 > height:\n",
    "                y2_shift = y2 - height\n",
    "                y2 = height\n",
    "\n",
    "            finger = contour[y1:y2, x1:x2]\n",
    "            cropped_kernel = kernel[y1_shift:kern_sz - y2_shift, x1_shift:kern_sz - x2_shift]\n",
    "            scores.append((finger * cropped_kernel).sum() - score_penalty)\n",
    "\n",
    "        end_points = [pt for pt, score in zip(end_points, scores) if score >= min_score]\n",
    "\n",
    "        return end_points\n",
    "    \n",
    "    skeleton = skeletonize (img / 255).astype(np.uint8)\n",
    "    endpoints = detect_endpts (skeleton)\n",
    "    \n",
    "    cont = get_contour (img / 255)\n",
    "    \n",
    "    endpoints = remove_endpts (cont, endpoints)\n",
    "    \n",
    "    notgray = cv2.cvtColor (img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    for endpoint in endpoints:\n",
    "        cv2.circle (notgray, (endpoint [1], endpoint [0]), 10, (100, 200, 3), -1)\n",
    "\n",
    "    notgray = cv2.putText (notgray, str(len (endpoints)), (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 255, 0), 7, cv2.LINE_AA)\n",
    "    \n",
    "    if (isinstance(cont, int)):\n",
    "        additional_stages = [skeleton * 255, notgray, notgray]\n",
    "    \n",
    "    else:\n",
    "        additional_stages = [skeleton * 255, cont.astype(np.uint8) * 255, notgray]\n",
    "    \n",
    "    return notgray\n",
    "\n",
    "det.add_filter (processor.custom_operation (lambda img: extract_and_filter_endpoints(img),\n",
    "                \"endpoints_extraction\"), \"fingers_counting\", \"endpoints extraction\")\n",
    "\n",
    "source = input_output.Source (\"../data/hand_gestures2.mkv\")\n",
    "output = input_output.Writer (\"output.mp4\", 1348, 759, 7)\n",
    "\n",
    "while (True):\n",
    "    _, frame = source.get_frame ()\n",
    "\n",
    "    mask, success = det.process (frame, \"fingers_counting\")\n",
    "\n",
    "    stages = det.get_stages_picts (\"fingers_counting\") [:-1]\n",
    "    \n",
    "    if (len (additional_stages) == 3):\n",
    "        stages += [additional_stages [0]]\n",
    "\n",
    "        if (not isinstance(additional_stages [1], int)):\n",
    "            stages += [additional_stages [1]]\n",
    "\n",
    "        stages += [additional_stages [2]]\n",
    "        \n",
    "    output_frame = input_output.form_grid (stages, 1350)\n",
    "    cv2.imshow (\"frame\", output_frame)\n",
    "    output.write (output_frame)\n",
    "    \n",
    "    time.sleep (0.02)\n",
    "\n",
    "    keyb = cv2.waitKey (1) & 0xFF\n",
    "    \n",
    "    if (keyb == ord('q')):\n",
    "        break\n",
    "\n",
    "source.release()\n",
    "output.release()\n",
    "\n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Нужно вводить ветвление: каждый фильтр должен принимать, что ему нужно на вход. Это\n",
    "требуется, чтобы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно вводить ветвление. Визуализация возможна через стрелки от предка к потомку.\n",
    "\n",
    "Структурно зрение очень напоминает весть проект целиком, то есть сборку\n",
    "конфигурации из модулей. Получается, что система сборки должна быть одной и той же,\n",
    "а модули разными.\n",
    "\n",
    "При этом система сборки может быть включена в один из модулей (зрение).\n",
    "Ассемблер (или скорее контейнер, который всех крутит и обновляет) получает на вход конфиг.\n",
    "Все модули должны уметь из коробки визуализировать, что они делают!!\n",
    "\n",
    "Модуль:\n",
    "инит (лист с входами)\n",
    "работатб ()\n",
    "\n",
    "Конфиг:\n",
    "\n",
    "модуль1:\n",
    "    config_path : smth.json\n",
    "    direct_config : конфиг, как например у зрения\n",
    "    inputs: []\n",
    "\n",
    "модуль2:\n",
    "    config_path : smth.json\n",
    "    direct_config : конфиг, как например у зрения\n",
    "    inputs: []\n",
    "\n",
    "Класс Container должен работать так же, как и все остальные. Хочется визуализации графа обработки данных, то есть кто кому дату отдает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Можно сделать у Source три режима чтения данных - реальный сенсор, симулятор, диск"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
